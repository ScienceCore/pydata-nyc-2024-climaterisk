{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d30b0b5-e7cd-4a20-908a-85f251db7e96",
   "metadata": {},
   "source": [
    "# Using the OPERA DSWx Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64adf3-0540-449b-b87c-ca6665629d9a",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://d2pn8kiwq2w21t.cloudfront.net/original_images/Opera-Hero-Overview-Infographic-v6.jpg\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "From the [OPERA (Observational Products for End-Users from Remote Sensing Analysis)](https://www.jpl.nasa.gov/go/opera) project:\n",
    "\n",
    ">Started in April 2021, the Observational Products for End-Users from Remote Sensing Analysis (OPERA) project at the Jet Propulsion Laboratory collects data from satellite radar and optical instruments to generate six product suites:\n",
    ">\n",
    "> + a near-global Surface Water Extent product suite\n",
    "> + a near-global Surface Disturbance product suite\n",
    "> + a near-global Radiometric Terrain Corrected product\n",
    "> + a North America Coregistered Single Look complex product suite\n",
    "> + a North America Displacement product suite\n",
    "> + a North America Vertical Land Motion product suite\n",
    "\n",
    "That is, OPERA is a NASA initiative that takes, e.g., optical or radar remote-sensing data gathered from satellites and produces a variety of pre-processed data sets for public use. OPERA products are not raw satellite images; they are the result of algorithmic classification to determine, e.g., which land regions contain water or where vegetation has been displaced. The raw satellite images are collected from measurements made by the instruments onboard the Sentinel-1 A/B, Sentinel-2 A/B, and Landsat-8/9 satellite missions (hence the term *HLS* for \"*Harmonized Landsat-Sentinel*\" in numerous product descriptions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72117edb-7d70-462b-af5d-aa1e4d8a051c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8131a58-330c-4e85-b274-635ed3dad2b5",
   "metadata": {},
   "source": [
    "## The OPERA Dynamic Surface Water Extent (DSWx) product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ecaec-03fd-4e10-a25e-c767f71c795e",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We've already looked at the DIST (i.e., land surface disturbance) family of OPERA data products. In this notebook, we'll examine another OPERA data product: the *Dynamic Surface Water Extent (DSWx)* product. This data product summarizes the extent of inland water (i.e., water on land masses as opposed to part of an ocean) that can be used to track flooding and drought events. The DSWx product is fully described in the [OPERA DSWx HLS product specification](https://d2pn8kiwq2w21t.cloudfront.net/documents/ProductSpec_DSWX_URS309746.pdf).\n",
    "\n",
    "The DSWx data products are generated from HLS surface reflectance (SR) measurements; specifically, these are made by the Operational Land Imager (OLI) aboard the Landsat 8 satellite, the Operational Land Imager 2 (OLI-2) aboard the Landsat 9 satellite, and the MultiSpectral Instrument (MSI) aboard the Sentinel-2A/B satellites. As with the DIST products, the DSWx products consist of raster data stored in GeoTIFF format using the [Military Grid Reference System (MGRS)](https://en.wikipedia.org/wiki/Military_Grid_Reference_System) (the details are fully described in the [DSWx product specification](https://d2pn8kiwq2w21t.cloudfront.net/documents/ProductSpec_DSWX_URS309746.pdf)). Again, the OPERA DSWx products are distributed as [Cloud Optimized GeoTIFFs](https://www.cogeo.org/) storing different bands/layers in distinct TIFF files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f96c60b-e3c3-46ed-93c0-faddd8376fc9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7236bda-6af4-4964-a305-7e2c8a05fb47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Band 1: Water classification (WTR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1397eb4b-0ff9-4790-bd40-11a007067989",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "There are ten bands or layers associated with the DSWx data product. In this tutorial, we will focus strictly on the first band&mdash;the *water classification (WTR)* layer&mdash;but details of all the bands are given in the [DSWx product specification](https://d2pn8kiwq2w21t.cloudfront.net/documents/ProductSpec_DSWX_URS309746.pdf). For instance, band 3 is the *Confidence (CONF)* layer that provides, for each pixel, quantitative values describing the degree of confidence in the categories given in band 1 (the Water classification layer). Band 4 is a *Diagnostic (DIAG)* layer that encodes, for each pixel, which of five tests were positive in deriving the corresponding pixel value in the CONF layer.\n",
    "\n",
    "The water classification layer consists of unsigned 8-bit integer raster data (UInt8) meant to represent whether a pixel contains inland water (e.g., part of a reservoir, a lake, a river, etc., but not water associated with the open ocean). The values in this raster layer are computed from raw images acquired by the satellite with pixels being assigned one of 7 positive integer values; we'll examine these below.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8a303-3fda-4d67-af71-f6ca8533c19c",
   "metadata": {},
   "source": [
    "### Examining an example WTR layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c38079-7a7f-4217-9e97-d092e1eb67dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Let's begin by importing the required libraries and loading a suitable file into an Xarray `DataArray`. The file in question contains raster data pertinent to the [Lake Powell reservoir](https://en.wikipedia.org/wiki/Lake_Powell) on the Colorado River in the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870af32b-dc5f-4f4a-9a81-a88ea327ebab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import rioxarray as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803988a8-e74f-43f1-91b1-ee4b440c62f3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import hvplot.pandas, hvplot.xarray\n",
    "import geoviews as gv\n",
    "gv.extension('bokeh')\n",
    "from bokeh.models import FixedTicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883c82f-1924-49fa-9e6f-87ac1741a805",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "LOCAL_PATH = Path().cwd() / '..' / 'assets' / 'OPERA_L3_DSWx-HLS_T12SVG_20230411T180222Z_20230414T030945Z_L8_30_v1.0_B01_WTR.tif'\n",
    "b01_wtr = rio.open_rasterio(LOCAL_PATH).rename({'x':'longitude', 'y':'latitude'}).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53617167-a721-4448-a54d-7d80c99ab2ef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Remember, using the repr for `b01_wtr` in this Jupyter notebook is quite convenient.\n",
    "+ By expanding the `Attributes` tab, we can see all the metadata associated with the data acquired.\n",
    "+ By expanding the `Coordinates` tab, we can examine all the associated arrays of coordinate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b175ea-4f6a-421c-8da4-2e25aa85f487",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Examine data\n",
    "b01_wtr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54215c8-c249-4743-b02d-f5652ebbed02",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Let's examine the distribution of pixel values in `b01_wtr` using the Pandas `Series.value_counts` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ec466-19ab-4c33-9c5f-e5175b8c7ce6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "counts = pd.Series(b01_wtr.values.flatten()).value_counts().sort_index()\n",
    "display(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ae7ddc-34af-49f5-b65b-db5dff7d86c9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "These pixel values are *categorical data*. Specifically, the valid pixel values and their meanings&mdash;according to the [DSWx product specification](https://d2pn8kiwq2w21t.cloudfront.net/documents/ProductSpec_DSWX_URS309746.pdf)&mdash;are as follows:\n",
    "\n",
    "+ **0**: Not Water&mdash;any area with valid reflectance data that is not from one of the other allowable categories (open water, partial surface water, snow/ice, cloud/cloud shadow, or ocean masked).\n",
    "+ **1**: Open Water&mdash;any pixel that is entirely water unobstructed to the sensor, including obstructions by vegetation, terrain, and buildings.\n",
    "+ **2**: Partial Surface Water&mdash;an area that is at least 50% and less than 100% open water (e.g., inundated sinkholes, floating vegetation, and pixels bisected by coastlines).\n",
    "+ **252**: Snow/Ice.\n",
    "+ **253**: Cloud or Cloud Shadow&mdash;an area obscured by or adjacent to cloud or cloud shadow.\n",
    "+ **254**: Ocean Masked&mdash;an area identified as ocean using a shoreline database with an added margin.\n",
    "+ **255**: Fill value (missing data).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f801e-8551-4150-b31a-97ff9261ff9e",
   "metadata": {},
   "source": [
    "### Producing an initial plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3329e332-a404-43d6-a94c-8ab638d8f57d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Let's make a first rough plot of the raster data using `hvplot.image`. As usual, we instantiate a `view` object that slices a smaller subset of pixels to make the image render quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974f996-6746-4501-86f9-4f6bec989c24",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image_opts = dict(\n",
    "                    x='longitude',\n",
    "                    y='latitude',                   \n",
    "                    rasterize=True, \n",
    "                    dynamic=True,\n",
    "                    project=True\n",
    "                 )\n",
    "layout_opts = dict(\n",
    "                    xlabel='Longitude',\n",
    "                    ylabel='Latitude',\n",
    "                    aspect='equal',\n",
    "                  )\n",
    "\n",
    "steps = 100\n",
    "subset = slice(0, None, steps)\n",
    "view = b01_wtr.isel(longitude=subset, latitude=subset)\n",
    "view.hvplot.image(**image_opts).opts(**layout_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484d8482-25eb-404c-8344-89c950157b12",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The default colormap does not reveal the raster features very well. Also, notice that the colorbar axis covers the numerical range from 0 to 255 (approximately) even though most of those pixel values (i.e., from `3` to `251`) do not actually occur in the data. Annotating a raster image of categorical data with a legend may make more sense than using a colorbar. However, at present, `hvplot.image` does not support using a legend. So, for this tutorial,  we'll stick to using a colorbar. Before assigning a colormap and appropriate labels for the colorbar, it makes sense to clean up the pixel values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f5663-b825-40ad-9a94-08cbd99007e1",
   "metadata": {},
   "source": [
    "### Reassigning pixel values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79c5b2e-4f4e-4141-893a-fe4434a7aeb4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We want to reassign the  raster pixel values to a tighter range (i.e., from `0` to `5` instead of from `0` to `255`) to make a sensible colorbar. To do this, we'll start by copying the values from the `DataArray` `b01_wtr` into another `DataArray` `new_data` and by creating an array `values` to hold the full range of permissible pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94415cb-e770-4fc4-9b27-c0696eb77d48",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "new_data = b01_wtr.copy(deep=True)\n",
    "values = np.array([0, 1, 2, 252, 253, 254, 255], dtype=np.uint8)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1811ebd-9e7f-44e7-ab67-d4e78d1667a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We first need to decide how to treat missing data, i.e., pixels with the value `255` in this raster. Let's choose to treat the missing data pixels the same as the `\"Not water\"` pixels. We can use the `DataArray.where` method to reassign pixels with value `null_val` (i.e., `255` in the code cell below) to the replacement value `transparent_val` (i.e., `0` in this case). Anticipating that we'll embed this code in a function later, we embed the computation in an `if`-block conditioned on a boolean value `replace_null`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5aff6-814a-4f1a-a600-bf9441035b11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "null_val = 255\n",
    "transparent_val = 0\n",
    "replace_null = True\n",
    "if replace_null:\n",
    "    new_data = new_data.where(new_data!=null_val, other=transparent_val)\n",
    "    values = values[np.where(values!=null_val)]\n",
    "\n",
    "print(np.unique(new_data.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf55c1-4ac7-4269-b07d-f6200067fb11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Notice that `values` no longer includes `null_val`. Next, instantiate an array `new_values` to store the replacement pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda5a73-4437-4190-bc5b-2d353aaa3766",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_values = len(values)\n",
    "start_val = 0\n",
    "new_values = np.arange(start=start_val, stop=start_val+n_values, dtype=values.dtype)\n",
    "assert transparent_val in new_values, f\"{transparent_val=} not in {new_values}\"\n",
    "print(values)\n",
    "print(new_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c63bcf-5bce-4751-af58-d6b2470df8a4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Now we combine `values` and `new_values` into a dictionary `relabel` and use the dictionary to modify the entries of `new_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae931c8d-2a0b-4e6a-ab68-c82c45e843a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2562aeb-9824-4212-9251-7682a11a6a1a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "relabel = dict(zip(values, new_values))\n",
    "for old, new in relabel.items():\n",
    "    if new==old: continue\n",
    "    new_data = new_data.where(new_data!=old, other=new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329846c-6292-4a28-a117-7b3f86a39b11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We can encapsulate the logic of the preceding cells into a utility function `relabel_pixels` that condenses a broad range of categorical pixel values into a tighter one that will display better with a colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0c4ab-3821-4827-b545-da218c77afbe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# utility to remap pixel values to a sequence of contiguous integers\n",
    "def relabel_pixels(data, values, null_val=255, transparent_val=0, replace_null=True, start=0):\n",
    "    \"\"\"\n",
    "    This function accepts a DataArray with a finite number of categorical values as entries.\n",
    "    It reassigns the pixel labels to a sequence of consecutive integers starting from start.\n",
    "    data:            Xarray DataArray with finitely many categories in its array of values.\n",
    "    null_val:        (default 255) Pixel value used to flag missing data and/or exceptions.\n",
    "    transparent_val: (default 0) Pixel value that will be fully transparent when rendered.\n",
    "    replace_null:    (default True) Maps null_value->transparent_value everywhere in data.\n",
    "    start:           (default 0) starting range of consecutive integer values for new labels.\n",
    "    The values returned are:\n",
    "    new_data:        Xarray DataArray containing pixels with new values\n",
    "    relabel:         dictionary associating old pixel values with new pixel values\n",
    "    \"\"\"\n",
    "    new_data = data.copy(deep=True)\n",
    "    if values:\n",
    "        values = np.sort(np.array(values, dtype=np.uint8))\n",
    "    else:\n",
    "        values = np.sort(np.unique(data.values.flatten()))\n",
    "    if replace_null:\n",
    "        new_data = new_data.where(new_data!=null_val, other=transparent_val)\n",
    "        values = values[np.where(values!=null_val)]\n",
    "    n_values = len(values)\n",
    "    new_values = np.arange(start=start, stop=start+n_values, dtype=values.dtype)\n",
    "    assert transparent_val in new_values, f\"{transparent_val=} not in {new_values}\"\n",
    "    relabel = dict(zip(values, new_values))\n",
    "    for old, new in relabel.items():\n",
    "        if new==old: continue\n",
    "        new_data = new_data.where(new_data!=old, other=new)\n",
    "    return new_data, relabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a776658a-f830-496c-b525-dfc88598bd7c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Let's apply the function just defined to `b01_wtr` and verify that the pixel values have been changed as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b78212-3bf5-4c7d-b3c7-5e836bd22fa8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "values = [0, 1, 2, 252, 253, 254, 255]\n",
    "print(f\"Before applying relabel_pixels: {np.unique(b01_wtr.values)}\")\n",
    "print(f\"Original pixel values expected: {values}\")\n",
    "b01_wtr, relabel = relabel_pixels(b01_wtr, values=values)\n",
    "print(f\"After applying relabel_pixels: {np.unique(b01_wtr.values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63632e-2401-4141-861b-f181ed97177b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Notice that the pixel value `5` does not occur in the relabelled array because the pixel value `254` (for \"Ocean Masked\" pixels) does not occur in the original GeoTIFF file. This is fine; the code writen below will still produce the full range of possible pixel values (& colors) in its colorbar.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a61a4d7-11a2-4fba-b4f9-d4197951b5db",
   "metadata": {},
   "source": [
    "### Defining a colormap & plotting with a colorbar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16218aa-b992-477d-9388-5b2c09e353ed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We are now ready to define a colormap. We define the dictionary `COLORS` so that the pixel labels from `new_values` are the dictionary keys and some RGBA color tuples used frequently for this kind of data are the dictionary values. We'll use variants of the code in the cell below to update `layout_opts` so that plots generated for various layers/bands from the DSWx data products have suitable legends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e23a7e-beb7-4932-bc2d-42797446cecf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "COLORS = {\n",
    "0: (255, 255, 255, 0.0),  # No Water\n",
    "1:  (0,   0, 255, 1.0),   # Open Water\n",
    "2:  (180, 213, 244, 1.0), # Partial Surface Water\n",
    "3: (  0, 255, 255, 1.0),  # Snow/Ice\n",
    "4: (175, 175, 175, 1.0),  # Cloud/Cloud Shadow\n",
    "5: ( 0,   0, 127, 0.5),   # Ocean Masked\n",
    "}\n",
    "\n",
    "c_labels = [\"No Water\", \"Open Water\", \"Partial Surface Water\", \"Snow/Ice\", \"Cloud/Cloud Shadow\", \"Ocean Masked\"]\n",
    "c_ticks = list(COLORS.keys())\n",
    "limits = (c_ticks[0]-0.5, c_ticks[-1]+0.5)\n",
    "\n",
    "print(c_ticks)\n",
    "print(c_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e71df4-8129-498b-a8f0-c260b2858113",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "To use this colormap, these ticks, and these labels in a colorbar, we create a ditionary `c_bar_opts` that holds the objects to pass to the Bokeh rendering engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7b4d5-64ff-4564-a0e0-262633ae97f1",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_bar_opts = dict( ticker=FixedTicker(ticks=c_ticks),\n",
    "                   major_label_overrides=dict(zip(c_ticks, c_labels)),\n",
    "                   major_tick_line_width=0, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13656704-59f2-4908-a815-648f6f0e287e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We need to update the dictionaries `image_opts` and `layout_opts` to include the data relevant to the colormap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc83a1-c286-49f9-ab2e-04481d6aba24",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_opts.update({ 'cmap': list(COLORS.values()),\n",
    "                    'clim': limits,\n",
    "                    'colorbar': True\n",
    "                  })\n",
    "\n",
    "layout_opts.update(dict(title='B01_WTR', colorbar_opts=c_bar_opts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d16b4f-df40-4385-9ba4-f3d1a609e3d8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Finally, we can render a quick plot to make sure that the colorbar is produced with suitable labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e3b98-7118-45f4-a33e-b1112e1d1825",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "steps = 100\n",
    "subset = slice(0, None, steps)\n",
    "view = b01_wtr.isel(longitude=subset, latitude=subset)\n",
    "view.hvplot.image( **image_opts).opts(frame_width=500, frame_height=500, **layout_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd585df2-6fe1-4d22-a9b8-899fe94d42ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Finally, we can define a basemap, this time using tiles from [ESRI](https://www.esri.com). This time, we'll plot plot the raster at full resolution (i.e., we won't bother using `isel` to select a lower-resolution slice from the raster first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bef8e5-26ce-4ff0-b3a5-a203e67564de",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates basemap\n",
    "base = gv.tile_sources.EsriTerrain.opts(padding=0.1, alpha=0.25)\n",
    "b01_wtr.hvplot(**image_opts).opts(**layout_opts) * base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd77c3ce-4dcc-4dc9-9627-f566aefea01a",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This notebook provides an overview of how to visualize data extracted from OPERA DSWx data products that are stored locally. We're now ready to automate the search for such products in the cloud using the PySTAC API.\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
