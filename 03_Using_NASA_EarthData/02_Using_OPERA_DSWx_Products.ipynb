{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d30b0b5-e7cd-4a20-908a-85f251db7e96",
   "metadata": {},
   "source": [
    "# Using the OPERA DSWx Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64adf3-0540-449b-b87c-ca6665629d9a",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<center>\n",
    "    <img src=\"https://d2pn8kiwq2w21t.cloudfront.net/original_images/Opera-Hero-Overview-Infographic-v6.jpg\" width=\"50%\"></img>\n",
    "</center>\n",
    "\n",
    "From the [OPERA (Observational Products for End-Users from Remote Sensing Analysis)](https://www.jpl.nasa.gov/go/opera) project:\n",
    "\n",
    ">Started in April 2021, the Observational Products for End-Users from Remote Sensing Analysis (OPERA) project at the Jet Propulsion Laboratory collects data from satellite radar and optical instruments to generate six product suites:\n",
    ">\n",
    "> + a near-global Surface Water Extent product suite\n",
    "> + a near-global Surface Disturbance product suite\n",
    "> + a near-global Radiometric Terrain Corrected product\n",
    "> + a North America Coregistered Single Look complex product suite\n",
    "> + a North America Displacement product suite\n",
    "> + a North America Vertical Land Motion product suite\n",
    "\n",
    "That is, OPERA is a NASA initiative that takes, e.g., optical or radar remote-sensing data gathered from satellites and produces a variety of pre-processed data sets for public use. OPERA products are not raw satellite images; they are the result of algorithmic classification to determine, e.g., which land regions contain water or where vegetation has been displaced. The raw satellite images are collected from measurements made by the instruments onboard the Sentinel-1 A/B, Sentinel-2 A/B, and Landsat-8/9 satellite missions (hence the term *HLS* for \"*Harmonized Landsat-Sentinel*\" in numerous product descriptions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72117edb-7d70-462b-af5d-aa1e4d8a051c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8131a58-330c-4e85-b274-635ed3dad2b5",
   "metadata": {},
   "source": [
    "## The OPERA Dynamic Surface Water Extent (DSWx) product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ecaec-03fd-4e10-a25e-c767f71c795e",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We've already looked at the DIST (i.e., land surface disturbance) family of OPERA data products. In this notebook, we'll examine another OPERA data product: the *Dynamic Surface Water Extent (DSWx)* product (more fully described in the [OPERA DSWx HLS product specification](https://d2pn8kiwq2w21t.cloudfront.net/documents/ProductSpec_DSWX_URS309746.pdf)). This data summarizes the extent of inland water (i.e., water on land masses as opposed to part of an ocean) that can be used to track flooding events.\n",
    "\n",
    "The DSWx data products are generated from HLS surface reflectance (SR) measurements; specifically, these are made by the Operational Land Imager (OLI) aboard the Landsat 8 satellite, the Operational Land Imager 2 (OLI-2) aboard the Landsat 9 satellite, and the MultiSpectral Instrument (MSI) aboard the Sentinel-2A/B satellites. As with the DIST products, the DSWx products consist of raster data stored in GeoTIFF format using the [Military Grid Reference System (MGRS)](https://en.wikipedia.org/wiki/Military_Grid_Reference_System) (the details are fully described in the [DSWx product specification](https://d2pn8kiwq2w21t.cloudfront.net/documents/ProductSpec_DSWX_URS309746.pdf)). Again, the OPERA DSWx products are distributed as [Cloud Optimized GeoTIFFs](https://www.cogeo.org/) storing different bands/layers in distinct TIFF files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f96c60b-e3c3-46ed-93c0-faddd8376fc9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7236bda-6af4-4964-a305-7e2c8a05fb47",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Band 1: Water classification (WTR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1397eb4b-0ff9-4790-bd40-11a007067989",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "There are ten bands or layers associated with the DSWx data product. For instance, band 3 is the *Confidence (CONF)* layer that provides, for each pixel, quantitative values describing the degree of confidence in the categories given in band 1 (the Water classification layer). Band 4 is a *Diagnostic (DIAG)* layer that encodes, for each pixel, which of five tests were positive in deriving the CONF layer. We will only use the first band — the *water classification (WTR)* layer — in this tutorial, but details of all the bands are given in the [DSWx product specification](https://d2pn8kiwq2w21t.cloudfront.net/documents/ProductSpec_DSWX_URS309746.pdf).\n",
    "\n",
    "The water classification layer consists of unsigned 8-bit integer raster data (UInt8) meant to represent whether a pixel contains inland water (e.g., part of a reservoir, a lake, a river, etc., but not water associated with the open ocean). The values in this raster layer are computed from raw images acquired by the satellite with pixels being assigned one of 7 positive integer values; we'll examine these below.\n",
    "\n",
    "Let's begin by importing the required libraries and loading a suitable file into an Xarray `DataArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a74066-bc4f-4323-be31-ee26035c8434",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Notebook dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "import rioxarray as rio\n",
    "import pandas as pd\n",
    "import hvplot.xarray\n",
    "from bokeh.models import FixedTicker\n",
    "import geoviews as gv\n",
    "gv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e883c82f-1924-49fa-9e6f-87ac1741a805",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "LOCAL_PATH = Path('..') / 'assets' / 'OPERA_L3_DSWx-HLS_T36RVU_20240601T082559Z_20240607T183514Z_S2B_30_v1.0_B01_WTR.tif'\n",
    "data = rio.open_rasterio(LOCAL_PATH)\n",
    "data = data.rename({'x':'easting', 'y':'northing', 'band':'band'}).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b175ea-4f6a-421c-8da4-2e25aa85f487",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Examine data\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc25dd6-09ea-41c6-98e4-962a0302e6ee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "As before, we define a basemap, this time using tiles from [ESRI](https://www.esri.com). We also set up dictionaries `image_opts` and `layout_opts` for common options we'll use when invoking `.hvplot.image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bef8e5-26ce-4ff0-b3a5-a203e67564de",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates basemap\n",
    "base = gv.tile_sources.EsriImagery.opts(width=1000, height=1000, padding=0.1)\n",
    "# Initialize image options dictionary\n",
    "image_opts = dict(\n",
    "                    x='easting',\n",
    "                    y='northing',                   \n",
    "                    rasterize=True, \n",
    "                    dynamic=True,\n",
    "                    frame_width=500, \n",
    "                    frame_height=500,\n",
    "                    aspect='equal',\n",
    "                    alpha=0.8\n",
    "                 )\n",
    "# Initialize layout options dictionary\n",
    "layout_opts = dict(\n",
    "                    xlabel='Longitude',\n",
    "                    ylabel='Latitude'\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269594cf-891c-4c1c-b1a7-d9dd9f7ce673",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "A continuous colormap is not all that helpful because this data is *categorical*. Specifically, the valid pixel values and their meanings are as follows:\n",
    "\n",
    "+ **0**: Not Water – an area with valid reflectance data that is not open water (class 1), partial surface water (class 2), snow/ice (class 252), cloud/cloud shadow (class 253), or ocean masked (class 254). Masking can result in “not water” (class 0) where land cover masking is applied.\n",
    "+ **1**: Open Water – an area that is entirely water and unobstructed to the sensor, including obstructions by vegetation, terrain, and buildings.\n",
    "+ **2**: Partial Surface Water – an area that is at least 50% and less than 100% open water (e.g., inundated sinkholes, floating vegetation, and pixels bisected by coastlines). This may be referred to as \"subpixel inundation\" when referring to a pixel's area.\n",
    "+ **252**: Snow/Ice.\n",
    "+ **253**: Cloud or Cloud Shadow – an area obscured by or adjacent to cloud or cloud shadow.\n",
    "+ **254**: Ocean Masked - an area identified as ocean using a shoreline database with an added margin\n",
    "+ **255**: Fill value (missing data).\n",
    "\n",
    "Let's count the number of pixels in each category using the Pandas `Series.value_counts` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313ec466-19ab-4c33-9c5f-e5175b8c7ce6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(data.values.flatten()).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2ca115-5b64-4dc3-b5fc-54735e944a45",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We'll choose color keys using the dictionary `color_key` with codes used frequently for this kind of data. For all the images plotted here, we'll use variants of the code in the cell below to update `layout_opts` so that plots generated for various layers/bands from the DSWx data products have suitable legends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f011ef6-8a77-4a25-8e55-39259c5d9f3f",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines colormap for visualization\n",
    "levels = [0, 0.9, 1.9, 2.9, 7.9, 8.9, 10]\n",
    "\n",
    "color_key = {\n",
    "    \"Not Water\": (255,255,255,0.5),\n",
    "    \"Open Water\": (0,0,255,1),\n",
    "    \"Partial Surface Water\": (0,255,0,1),\n",
    "    \"Reserved\": (0,0,0,1),\n",
    "    \"Snow/Ice\": (0,255,255,1),\n",
    "    \"Clouds/Cloud Shadow\": (127,127,127,0.25)\n",
    "}\n",
    "\n",
    "ticks = [0.5, 1.5, 2.5, 5.5, 8.5, 9.5]\n",
    "ticker = FixedTicker(ticks=ticks)\n",
    "labels = dict(zip(ticks, color_key))\n",
    "\n",
    "layout_opts.update(\n",
    "                    title='B01_WTR',\n",
    "                    color_levels=levels,\n",
    "                    cmap=tuple(color_key.values()),\n",
    "                    colorbar_opts={'ticker':ticker,'major_label_overrides':labels}\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8113cc1-43b0-4ecd-a9a7-4e6536004a87",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "b01_wtr = data.where((data!=255) & (data!=0))\n",
    "image_opts.update(crs=data.rio.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e3b98-7118-45f4-a33e-b1112e1d1825",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "b01_wtr.hvplot.image(**image_opts).opts(**layout_opts) * base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f5ab6-ef25-487b-ac6b-5f8f1107f3e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The plot shows the southern end of the Suez Canal. Much of the region in the scene is land; some areas of open water are visible but most is obscured by cloud cover."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e8e7b-b07b-42e3-a1a6-ffe826a11e43",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e300752d-49e2-45c5-8b7a-f0f3219b33b1",
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This notebook provides an overview of how to visualize data extracted from OPERA DSWx data products that are stored locally. We're now ready to automate the search for such products in the cloud using the PySTAC API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd94a391-96e0-457c-9c40-747932119d59",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
