{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245011b7-9455-47cd-83a0-1495bb8984dd",
   "metadata": {},
   "source": [
    "# The Great Green Wall in Senegal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291b38a-51ba-4b68-beb0-c0a4b5d40363",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "[The Great Green Wall](https://en.wikipedia.org/wiki/Great_Green_Wall_(Africa)) is an effort to combat the spread of the Sahara desert by growing vegetation in a systematic and scientific manner. The [OPERA DIST-ALERT data product](https://lpdaac.usgs.gov/documents/1766/OPERA_DIST_HLS_Product_Specification_V1.pdf) can also be used to identify changes in the growth of vegetation (implying natural or, in this case, anthropogenic causes).\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Sahara_satellite_hires.jpg/800px-Sahara_satellite_hires.jpg\"></img>\n",
    "</center>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84af60-83ac-45f5-ae03-7c977c4af7cd",
   "metadata": {},
   "source": [
    "## Outline of steps for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291cef0-6f4f-468a-997d-27890392951f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "+ Identifying search parameters (AOI, time-window, endpoint, etc.)\n",
    "+ Obtaining search results in a `DataFrame`\n",
    "+ Exploring & refining search results\n",
    "+ Data-wrangling to produce relevant output\n",
    "\n",
    "In this case, we'll assemble a DataFrame to summarize search results, trim down the results to a manageable size, and make an interactive slider to examine the data retrieved.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9030e8-ec21-4ac7-8689-bf42cd23ac8b",
   "metadata": {},
   "source": [
    "### Preliminary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb10a73-9be7-4647-a03c-3a2510b7e652",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import rioxarray as rio\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b0813-1566-45b9-b8f3-2d61486acf4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import hvplot.pandas, hvplot.xarray\n",
    "import geoviews as gv\n",
    "from geoviews import opts\n",
    "gv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b451e-7913-418e-8885-0cd28ba04c02",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from osgeo import gdal\n",
    "# GDAL setup for accessing cloud data\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEFILE','~/.cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEJAR', '~/.cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN','EMPTY_DIR')\n",
    "gdal.SetConfigOption('CPL_VSIL_CURL_ALLOWED_EXTENSIONS','TIF, TIFF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9ec09a-4c34-4fd1-a563-fc7ff6988aae",
   "metadata": {},
   "source": [
    "### Convenient utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0acb1-10ea-4157-8d5f-f8346823496a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# simple utility to make a rectangle with given center of width dx & height dy\n",
    "def make_bbox(pt,dx,dy):\n",
    "    '''Returns bounding-box represented as tuple (x_lo, y_lo, x_hi, y_hi)\n",
    "    given inputs pt=(x, y), width & height dx & dy respectively,\n",
    "    where x_lo = x-dx/2, x_hi=x+dx/2, y_lo = y-dy/2, y_hi = y+dy/2.\n",
    "    '''\n",
    "    return tuple(coord+sgn*delta for sgn in (-1,+1) for coord,delta in zip(pt, (dx/2,dy/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80a32a-ad1f-4b2b-8feb-ac6ebce4dea8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# simple utility to plot an AOI or bounding-box\n",
    "def plot_bbox(bbox):\n",
    "    '''Given bounding-box, returns GeoViews plot of Rectangle & Point at center\n",
    "    + bbox: bounding-box specified as (lon_min, lat_min, lon_max, lat_max)\n",
    "    Assume longitude-latitude coordinates.\n",
    "    '''\n",
    "    # These plot options are fixed but can be over-ridden\n",
    "    point_opts = opts.Points(size=12, alpha=0.25, color='blue')\n",
    "    rect_opts = opts.Rectangles(line_width=0, alpha=0.1, color='red')\n",
    "    lon_lat = (0.5*sum(bbox[::2]), 0.5*sum(bbox[1::2]))\n",
    "    return (gv.Points([lon_lat]) * gv.Rectangles([bbox])).opts(point_opts, rect_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d876c-f625-40e6-ae47-d893b57f60b5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# utility to extract search results into a Pandas DataFrame\n",
    "def search_to_dataframe(search):\n",
    "    '''Constructs Pandas DataFrame from PySTAC Earthdata search results.\n",
    "    DataFrame columns are determined from search item properties and assets.\n",
    "    'asset': string identifying an Asset type associated with a granule\n",
    "    'href': data URL for file associated with the Asset in a given row.'''\n",
    "    granules = list(search.items())\n",
    "    assert granules, \"Error: empty list of search results\"\n",
    "    props = list({prop for g in granules for prop in g.properties.keys()})\n",
    "    tile_ids = map(lambda granule: granule.id.split('_')[3], granules)\n",
    "    rows = (([g.properties.get(k, None) for k in props] + [a, g.assets[a].href, t])\n",
    "                for g, t in zip(granules,tile_ids) for a in g.assets )\n",
    "    df = pd.concat(map(lambda x: pd.DataFrame(x, index=props+['asset','href', 'tile_id']).T, rows),\n",
    "                   axis=0, ignore_index=True)\n",
    "    assert len(df), \"Empty DataFrame\"\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5d96499-12a4-4d36-bb04-932c1a2ba429",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "These functions could be placed in module files for more developed research projects. For learning purposes, they are embedded within this notebook.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b731a-4382-4019-9da8-faac4f05011d",
   "metadata": {},
   "source": [
    "## Obtaining search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe2ed55-54a6-41d8-9fa4-f299dd6b4408",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The Great Green Wall spans the African continent; we'll choose an area-of-interest centered at the geographic coordinates $(-16.0913^{\\circ}, 16.528^{\\circ})$ in Senegal. We'll look at as much data as is available from January 2022 until the end of March 2024. We'll use the identifiers `AOI` and `DATE_RANGE` to eventually be used in a PySTAC search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1c0ce-876d-415b-8c41-694a620caee7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "AOI = make_bbox((-16.0913, 16.528), 0.1, 0.1)\n",
    "DATE_RANGE = \"2022-01-01/2024-03-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ac4c9-e83e-4832-8726-dfcd372c3223",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The plot generated below illustrates the AOI; the Bokeh Zoom tools are useful to examine the box on several length scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf723fd-cc11-45bf-802e-e975817559b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Optionally plot the AOI\n",
    "basemap = gv.tile_sources.OSM(padding=0.1, alpha=0.25)\n",
    "plot_bbox(AOI) * basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab3f86-396e-4ac7-9a08-bea7539fd1fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "search_params = dict(bbox=AOI, datetime=DATE_RANGE)\n",
    "print(search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea987687-d1e8-4812-a997-51eca00f1ab1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "To execute the search, we define the endpoint URI and instantiate a `Client` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd0076-af2f-4d8e-ad32-446fc182c19c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ENDPOINT = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "PROVIDER = 'LPCLOUD'\n",
    "COLLECTIONS = [\"OPERA_L3_DIST-ALERT-HLS_V1_1\"]\n",
    "search_params.update(collections=COLLECTIONS)\n",
    "print(search_params)\n",
    "\n",
    "catalog = Client.open(f'{ENDPOINT}/{PROVIDER}/')\n",
    "search_results = catalog.search(**search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a36d4f-9c2d-437e-b4bd-e5ecfed6d606",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The search itself is quite fast and yields a few thousand results that can be more easily examined in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b53cc2b-80f5-4222-b9c8-98e7cd9faf5b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = search_to_dataframe(search_results)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b9b0a-7074-4246-a231-a5e167b80ec2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We clean the `DataFrame` `df` in typical ways that make sense:\n",
    "+ renaming the `eo:cloud_cover` column as `cloud_cover`;\n",
    "+ dropping extraneous `datetime` columns;\n",
    "+ casting columns to sensible datatypes;\n",
    "+ casting the `datetime` column as `DatetimeIndex`; and\n",
    "+ setting the `datetime` column as the `Index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d0b86f-4f73-497c-9225-826e490271b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'eo:cloud_cover':'cloud_cover'})\n",
    "df.cloud_cover = df.cloud_cover.astype(np.float16)\n",
    "df = df.drop(['start_datetime', 'end_datetime'], axis=1)\n",
    "df = df.convert_dtypes()\n",
    "df.datetime = pd.DatetimeIndex(df.datetime)\n",
    "df = df.set_index('datetime').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1703aa0e-1378-406d-8e19-1d331aa67fbe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf054d-7e34-4114-a030-ca098baee8f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The next step is to identify a smaller set of rows from the search results that we can work with more easily.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f04677-4e12-4405-b3f9-6cb90382c4bf",
   "metadata": {},
   "source": [
    "## Exploring & refining search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6301d5c-8b9d-4c1b-ac4c-90c80ac787df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The `VEG-DIST-STATUS` band of the DIST-ALERT data is what we want, so we need to extract only those rows from `df` that are associated with that particular band. To do so, we can construct a boolean series `c1` that is `True` whenever the string in the `asset` column includes `VEG-DIST-STATUS` as a sub-string. We can also construct a boolean series `c2` to filter out rows for which the `cloud_cover` exceeds 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822a2845-2c18-4421-91ff-1e0728027dbd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "c1 = df.asset.str.contains('VEG-DIST-STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec89a65-c5c4-40d4-a306-797275e3e141",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "c2 = df.cloud_cover<20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd2b94d-8d4f-4fd7-be88-786d0257125d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "If we examine the `tile_id` column, we can see that a single MGRS tile contains the AOI we specified. As such, all the data indexed in `df` corresponds to distinct measurements taken from a fixed geographic tile at different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc25ab46-11d1-48c5-a5a6-1eb3af1961d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.tile_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a9b62a-3453-4f78-bd64-96bf204bd4fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We can combine the information above to reduce the `DataFrame` to a much shorter sequence of rows. We can also drop the `asset` and `tile_id` columns because they will be the same in every row after filtering. We can also drop the `cloud_cover` as we really only need the `href` column going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f06f8-7fc1-44f5-9002-94c438e4c983",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.loc[c1 & c2].drop(['asset', 'tile_id', 'cloud_cover'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837d117-7869-4206-ab5e-4b480572ef13",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a93a1e2-d4e1-473b-ba9e-c467cf92b792",
   "metadata": {},
   "source": [
    "## Data-wrangling to produce relevant output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d0b3d-f74a-40bb-930f-6ebe75361d11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We can examine the resulting `DataFrame` to see what information remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35934857-c787-469e-be00-fcc1c815cbaa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7d0bb4-63a5-4148-ab8c-176ceceabc63",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "There are almost eighty rows, each of which is associated with a distinct granule (in this context, a GeoTIFF file produced from an observation made at a given timestamp). We'll use a loop to assemble a stacked `DataArray` from the remote files using `xarray.concat`. Given that a few dozen files need to be retrieved from a remote source, this can take a few minutes and the result will require some memory (about 12 MiB for each row since each GeoTIFF corresponds to a $3,660\\times3,660$ array of 8-bit unsigned integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee8daef-22d3-4305-8a7e-274db37719c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "stack = []\n",
    "for timestamp, row in df.iterrows():\n",
    "    data = rio.open_rasterio(row.href).squeeze()\n",
    "    data = data.rename(dict(x='longitude', y='latitude'))\n",
    "    del data.coords['band']\n",
    "    data.coords.update({'time':timestamp})\n",
    "    data.attrs = dict(description=f\"OPERA DIST: VEG-DIST-STATUS\", units=None)\n",
    "    stack.append(data)\n",
    "stack = xr.concat(stack, dim='time')\n",
    "stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442bd84e-e43a-4953-aa84-0ac3a71b9a0d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "As a reminder, for the `VEG-DIST-STATUS` band, we interpret the raster values as follows:\n",
    "\n",
    "* **0:** No disturbance\n",
    "* **1:** First detection of disturbance with vegetation cover change <50%\n",
    "* **2:** Provisional detection of disturbance with vegetation cover change <50%\n",
    "* **3:** Confirmed detection of disturbance with vegetation cover change <50%\n",
    "* **4:** First detection of disturbance with vegetation cover change ≥50%\n",
    "* **5:** Provisional detection of disturbance with vegetation cover change ≥50%\n",
    "* **6:** Confirmed detection of disturbance with vegetation cover change ≥50%\n",
    "* **7:** Finished detection of disturbance with vegetation cover change <50%\n",
    "* **8:** Finished detection of disturbance with vegetation cover change ≥50%\n",
    "* **255** Missing data\n",
    "\n",
    "By applying `np.unique` to the stack of rasters, we see that all these 10 distinct values occur somewhere in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9777d-0775-49bb-afa0-82d2898057d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.unique(stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea6d8b3-1207-4d5e-a458-7fd68f4225fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We'll treat the pixels with missing values (i.e., value `255`) the same as pixels with no disturbance (i.e., value `0`). We could reassign the value `nan` to those pixels, but that converts all the data to `float32` or `float64` and hence increases the amount of memory required. That is, reassigning `255->0` allows us to ignore the missing values without using more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38176a5-56b0-4d13-9fea-e0fa844feb58",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stack = stack.where(stack!=255, other=0)\n",
    "\n",
    "np.unique(stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61968d40-9c06-4fe4-8951-fb154eb63b8c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We'll define a colormap to identify pixels showing signs of disturbance. Rather than assigning different colors to each of the 8 disturbance categories, we'll use [RGBA](https://en.wikipedia.org/wiki/RGBA_color_model) values to assign colors with a transparency value. With the colormap defined in the next cell, most of the pixels will be fully transparent. The remaining pixels are red with strictly positive `alpha` values. The values we really want to see are `3`, `6`, `7`, & `8` (indicating confirmed ongoing disturbance or confirmed disturbance that has finished)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92380b-4b8d-4b89-b8f1-4ede799d84ed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define a colormap using RGBA values; these need to be written manually here...\n",
    "COLORS = [\n",
    "            (255, 255, 255, 0.0),   # No disturbance\n",
    "            (255,   0,   0, 0.25),  # <50% disturbance, first detection\n",
    "            (255,   0,   0, 0.25),  # <50% disturbance, provisional\n",
    "            (255,   0,   0, 0.50),  # <50% disturbance, confirmed, ongoing\n",
    "            (255,   0,   0, 0.50),  # ≥50% disturbance, first detection\n",
    "            (255,   0,   0, 0.50),  # ≥50% disturbance, provisional\n",
    "            (255,   0,   0, 1.00),  # ≥50% disturbance, confirmed, ongoing\n",
    "            (255,   0,   0, 0.75),  # <50% disturbance, finished\n",
    "            (255,   0,   0, 1.00),  # ≥50% disturbance, finished\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c73382d-72a6-4cbe-8181-6de9769e14a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Finally, we're ready to produce visualizations using the array `stack`. \n",
    "\n",
    "+ We define `view` as a subset of `stack` that skips `steps` pixels in each direction to speed rendering (change to `steps=1` or `steps=None` when ready to plot at full resolution).\n",
    "+ We define dictionaries `image_opts` and `layout_opts` to control arguments to pass to `hvplot.image`.\n",
    "+ The result, when plotted, is an interactive plot with a slider that allows us to view specific time slices of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41baf25-74ce-4fa5-8da2-dd7a01ec5fc3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "steps = 100\n",
    "subset=slice(0,None,steps)\n",
    "view = stack.isel(longitude=subset, latitude=subset)\n",
    "\n",
    "image_opts = dict(\n",
    "                    x='longitude',\n",
    "                    y='latitude',\n",
    "                    cmap=COLORS,\n",
    "                    colorbar=False,\n",
    "                    clim=(-0.5,8.5),\n",
    "                    crs = stack.rio.crs,\n",
    "                    tiles=gv.tile_sources.ESRI,\n",
    "                    tiles_opts=dict(alpha=0.1, padding=0.1),\n",
    "                    project=True,\n",
    "                    rasterize=True,\n",
    "                    widget_location='bottom',\n",
    "                 )\n",
    "\n",
    "layout_opts = dict(\n",
    "                    title = 'Great Green Wall, Sahel Region, Africa\\nDisturbance Alerts',\n",
    "                    xlabel='Longitude (°)',ylabel='Latitude (°)',\n",
    "                    fontscale=1.25,\n",
    "                    frame_width=500,\n",
    "                    frame_height=500,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86f536b-da9f-47bd-9a60-4ccf7b7e9bd9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "view.hvplot.image(**image_opts, **layout_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee80d4-b188-47a0-aed7-0c380da29dd2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "source": [
    "It can be difficult to see the red pixels with the entire region in view; the box zoom and wheel zoom tools are useful here. There is also some latency when using the slider as it takes some time to render a new slice.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
